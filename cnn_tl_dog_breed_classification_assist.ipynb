{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_tl_dog_breed_classification_assist",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skimaza/assist/blob/main/cnn_tl_dog_breed_classification_assist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlyXgftgToet"
      },
      "source": [
        "# AI 전략경영MBA 경영자를 위한 딥러닝 원리의 이해\n",
        "# Convolutional Neural Network 전이학습 실습 예제\n",
        "# 전이학습을 이용한 견종 분류\n",
        "- https://github.com/Ahmad-shaikh575/dog-breed-classifier 예제를 이용했음  \n",
        "- 예제를 설명하는 글은 https://levelup.gitconnected.com/dog-breed-classifier-with-pytorch-using-transfer-learning-8f15af6f9010"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw3-Ixe8LTtN"
      },
      "source": [
        "# 실행전에 Colab 메뉴에서 런타임->런타임 유형변경을 선택하여 하드웨어 가속기가 GPU로 선택되었는지 확인\n",
        "### GPU를 사용하지 않아도 실행할 수 있으나 학습에 시간이 오래 걸림"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqFUB4PMT4Iv"
      },
      "source": [
        "# 학습에 사용할 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpiVzENuVgx2"
      },
      "source": [
        "- urllib 라이브러리의 request 모듈의 urlretrieve 함수를 이용 (https://docs.python.org/3/library/urllib.request.html)  \n",
        "- 첫번째 인자는 URL, 두번째 인자는 저장할 파일명  \n",
        "- (주의) urlretrieve를 사용할 때 두번째 인자를 지정하지 않으면 임시 디렉토리(/tmp)에 임의의 이름으로 저장됨."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PPSHq9ngwcW"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip', 'dogImages.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW8BWpBnNSbv"
      },
      "source": [
        "## 아래 코드는 다운로드가 안 되는 경우를 위한 코드\n",
        "### 라인 앞의 '#'을 지우고 실행\n",
        "- (주의) 이번 파일은 크기가 커서 MLP 예제와 다르게 wget 명령문에서 복잡한 처리를 해줘야 다운로드가 성공함\n",
        "- 다운로드후 '!ls -l' 명령 결과 dogImages.zip 파일크기가 1132023110 바이트인지 꼭 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBGLpZ6TQJbo"
      },
      "source": [
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JQ-A69KBwYlS1yFNP2Yz2K5dwysgcxcB' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JQ-A69KBwYlS1yFNP2Yz2K5dwysgcxcB\" -O dogImages.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXv1jjAvZx-d"
      },
      "source": [
        "# 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzczGUSWrMu_"
      },
      "source": [
        "dogImages.zip이 다운로드됐는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvysx8h_XW8S"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2siFF-l1Y6-3"
      },
      "source": [
        "압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9RkEwKyg-7x"
      },
      "source": [
        "!unzip 'dogImages.zip' > /dev/null  # 화면 출력 메시지를 표시하지 않기 위해 뒤에 \"> /dev/null\"을 붙였음. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzecWH5Y-ve"
      },
      "source": [
        "!ls dogImages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZqJn9IZRtmW"
      },
      "source": [
        "이미 train, valid, test 데이터셋이 구분되어 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCvvxavlZg1F"
      },
      "source": [
        "!ls dogImages/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tfM_uwSZkqG"
      },
      "source": [
        "### 133 종류의 개 이미지가 디렉토리별로 저장되어 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2P4yvQkZDR1"
      },
      "source": [
        "!ls dogImages/train/001.Affenpinscher/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBixbRd0alks"
      },
      "source": [
        "!ls dogImages/train/133.Yorkshire_terrier/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK0cvpNFZaa9"
      },
      "source": [
        "!ls dogImages/valid/001.Affenpinscher/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntyleYw-ZSwT"
      },
      "source": [
        "!ls dogImages/test/001.Affenpinscher/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij8UP72BZPx3"
      },
      "source": [
        "### 데이터셋을 본 후 간단한 요약\n",
        "- 데이터는 train, valid, test 디렉토리로 구분되어 있음\n",
        "- 각 디렉토리에는 133개 견종 디렉토리가 'ddd.breed' 형식으로 구성되어 있음\n",
        "- 견종 디렉토리에는 'breed_ddddd.jpg' 형식의 이름을 갖는 jpg 이미지 파일들이 있음\n",
        "- 견종 디렉토리에 있는 이미지의 개수는 견종별로 일치하지 않는 것 같음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAAKp5YWbaui"
      },
      "source": [
        "### 전체 데이터에 대한 분포를 확인하여 위 요약을 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POBNZgI8b7RM"
      },
      "source": [
        "glob는 디렉토리에서 파일리스트를 읽어오는 라이브러리  \n",
        "읽어온 결과의 순서는 이름순이 아님"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPsz1cC5baru"
      },
      "source": [
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZityKvKUbanY"
      },
      "source": [
        "datadir = 'dogImages'\n",
        "train_breed_dirs = glob(datadir + '/train/*')\n",
        "valid_breed_dirs = glob(datadir + '/valid/*')\n",
        "test_breed_dirs = glob(datadir + '/test/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xz3arXyS8Vk"
      },
      "source": [
        "학습데이터셋 크기와 처음 10가지 종류 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQgf6N79bakv"
      },
      "source": [
        "print(len(train_breed_dirs))\n",
        "print(train_breed_dirs[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-6aHBS8fBdq"
      },
      "source": [
        "len(valid_breed_dirs), len(test_breed_dirs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I48D8CsQc5VE"
      },
      "source": [
        "순서가 섞여서 보기 어려움  \n",
        "natsort 패키지를 이용해서 사람이 보는 방식으로 정렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqVDBdJPbaZi"
      },
      "source": [
        "from natsort import natsorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65QxBcCtc4jv"
      },
      "source": [
        "train_breed_dirs = natsorted(train_breed_dirs)\n",
        "valid_breed_dirs = natsorted(valid_breed_dirs)\n",
        "test_breed_dirs = natsorted(test_breed_dirs)\n",
        "train_breed_dirs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEb5SOe4T2Iz"
      },
      "source": [
        "정렬이 되었음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWqukNi9c4hT"
      },
      "source": [
        "### train_breed_dirs 안에 있는 파일 개수 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GImf3eeVUiXK"
      },
      "source": [
        "plotting을 위해 names에 디렉토리, train_counts에 디렉토리의 이미지 개수를 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWCPk3qcc4cg"
      },
      "source": [
        "names = []\n",
        "train_counts = []\n",
        "for d in train_breed_dirs:\n",
        "    breed_name = d.split('/')[-1]\n",
        "    image_count = len(glob(d + '/*.jpg'))\n",
        "    names.append(breed_name)\n",
        "    train_counts.append(image_count)\n",
        "    print(\"{:40}: {} images for train\".format(breed_name, image_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCTDP8ZyUKeE"
      },
      "source": [
        "names 제일 끝 3개의 요소와 데이터수 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nquJXX5hQ-S"
      },
      "source": [
        "names[-3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mng8CWbVhWYE"
      },
      "source": [
        "train_counts[-3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhZ7sXfuUz_Y"
      },
      "source": [
        "# plotting을 위해 pyplot 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAA3zISkhkBW"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyKkLAWsjJ1K"
      },
      "source": [
        "그림 크기를 키우기 위해 디폴트 설정을 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P74-Rmifigix"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (20, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3m8bYT7VC_I"
      },
      "source": [
        "클래스별(디렉토리별)로 train data 개수를 플로팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQtwsSJQhffD"
      },
      "source": [
        "plt.plot(names, train_counts)\n",
        "plt.xticks(rotation=90, fontsize=10);    # 여기에 세미콜론을 넣어서 주피터에서 xticks의 리턴값을 보여주지 않도록 지정했다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAIJr9VfVbcY"
      },
      "source": [
        "valid와 test data에 대해서 동일한 플로팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ORhZ_Hac4aL"
      },
      "source": [
        "valid_counts = []\n",
        "for d in valid_breed_dirs:\n",
        "    breed_name = d.split('/')[-1]\n",
        "    image_count = len(glob(d + '/*.jpg'))\n",
        "    # names.append(breed_name)  # names는 train에서 이미 구했으므로 여기서 다시 모을 필요없음\n",
        "    valid_counts.append(image_count)\n",
        "    print(\"{:40}: {} images for validation\".format(breed_name, image_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvDUu4f8kteT"
      },
      "source": [
        "plt.plot(names, valid_counts)\n",
        "plt.xticks(rotation=90, fontsize=10);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9kEEuPjc4VM"
      },
      "source": [
        "test_counts = []\n",
        "for d in test_breed_dirs:\n",
        "    breed_name = d.split('/')[-1]\n",
        "    image_count = len(glob(d + '/*.jpg'))\n",
        "    test_counts.append(image_count)\n",
        "    print(\"{:40}: {} images for test\".format(breed_name, image_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qru0n1hlKKS"
      },
      "source": [
        "plt.plot(names, test_counts)\n",
        "plt.xticks(rotation=90, fontsize=10);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxs6VJ9sV1zD"
      },
      "source": [
        "train, valid, test count를 한꺼번에 플로팅하여 데이터수를 상대적으로 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-B6a6tNWY7m"
      },
      "source": [
        "pyplot은 한 셀에서는 plt.show()를 실행하거나 셀이 끝나기 전까지 같은 그래프에 그려준다.  \n",
        "셀이 나눠지면 다른 그림이 나오게 되므로 아래 명령은 한 셀에서 실행해야 한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5eQ9Z7FlPJv"
      },
      "source": [
        "plt.plot(names, train_counts, label='train')\n",
        "plt.plot(names, valid_counts, label='valid')\n",
        "plt.plot(names, test_counts, label='test')\n",
        "plt.legend(fontsize=18)\n",
        "plt.xticks(rotation=90, fontsize=10)\n",
        "plt.show() # 같은 셀에서 실행하고 있으므로 이 명령은 필요없다. 여러 데이터를 한 그래프에 표시하는 기능을 명확히 표시하기 위해 넣어두었음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezFVkjO5XWKk"
      },
      "source": [
        "train은 클래스당 35-75개, valid와 test는 클래스당 5-10개 수준임을 확인할 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdbG9cksw3A"
      },
      "source": [
        "# 이미지를 직접 확인하자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZZCB6u7XqaO"
      },
      "source": [
        "## PIL(Python Image Library)은 파이썬에서 이미지를 처리하는 라이브러리 중 하나"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vpwuplzs811"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMV1EXNKYKr8"
      },
      "source": [
        "train_breed_dirs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoBD7qqFYahd"
      },
      "source": [
        "glob(train_breed_dirs[0] + '*/*.jpg')[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19Fqd-DbYEiq"
      },
      "source": [
        "train_breed_dirs의 첫번째 디렉토리(dogImages/train/001.Affenpinscher)에서 모든 .jpg 파일을 읽고 그 중 첫번째 파일을 읽어들인다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilfhoHzRsyyK"
      },
      "source": [
        "filename = glob(train_breed_dirs[0] + '/*.jpg')[0]\n",
        "print(filename)\n",
        "tr_affen_img = Image.open(filename)\n",
        "plt.imshow(np.asarray(tr_affen_img));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ6u6eJHY6t_"
      },
      "source": [
        "### 두 종류에 대해서 이미지 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUyoksIUtud1"
      },
      "source": [
        "for d in train_breed_dirs[:2]:\n",
        "    filename = glob(d + '/*.jpg')[0]\n",
        "    img = Image.open(filename)\n",
        "    plt.imshow(np.asarray(img))\n",
        "    print(filename)\n",
        "    print('디렉토리', d.split('/')[-1])\n",
        "    plt.show(); # 그림을 여러개 그리기 때문에 매번 plt.show()를 해서 화면에 표시한다. 주피터 노트북 각 셀에서는 마지막에 자동으로 show를 처리해 주기 때문에 앞선 예제에서는 이 명령이 생략되었었다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybNrJqa0ZhZP"
      },
      "source": [
        "## 여러 클래스 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0XbcIZotDvK"
      },
      "source": [
        "계산에 사용할 파이썬 내장 나머지와 몫 연산 기능 확인  \n",
        "파이썬 //(나눗셈 몫), %(나머지)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vod5LGGwIbr"
      },
      "source": [
        "print('0/10의 몫과 나머지', 0 // 10, 0 % 10)\n",
        "print('132/10의 몫과 나머지', 132 // 10, 132 % 10)\n",
        "print('139/10의 나머지', 139//10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SVp_94J4Rfw"
      },
      "source": [
        "40개만 그려보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWTRlxEduiU0"
      },
      "source": [
        "fig, axes = plt.subplots(4, 10, figsize=(30,15)) # 4 rows, 10 columns 형태로 여러 이미지 그리기\n",
        "for ind, d in enumerate(train_breed_dirs[:40]):\n",
        "    breed_idx_name = d.split('/')[-1]\n",
        "    img = np.asarray(Image.open(glob(d + '/*.jpg')[0]))\n",
        "    row = ind // 10 # 한 줄에 10개씩 그리기\n",
        "    col = ind % 10 # 한 줄 안에서 순서\n",
        "    axes[row, col].imshow(img)\n",
        "    axes[row, col].set_title(breed_idx_name)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close(fig) # subplots의 fig를 close 하지 않으면 메모리가 반환되지 않아서 가용메모리가 점차 줄어든다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBj1Bl1_jO4h"
      },
      "source": [
        "\n",
        "# load filenames for human and dog images\n",
        "dog_files = np.array(glob(\"/content/dogImages/*/*/*\"))\n",
        "# print number of images in each dataset\n",
        "print('There are %d total dog images.' % len(dog_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYqFOuo0sS5J"
      },
      "source": [
        "# Pretrained model download\n",
        "전이학습을 위해 이미지넷으로 학습된 모델을 다운로드  \n",
        "예제에서는 VGG11 CNN 모델을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSi4gDb6jSv1"
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# define VGG11 model\n",
        "VGG11 = models.vgg11(pretrained=True)\n",
        "\n",
        "# check if CUDA is available\n",
        "# Colab 시작할 때 런타임 유형을 GPU로 선택했으면 torch.cuda.is_available()가 True\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    VGG11 = VGG11.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKHUs4wbpIt"
      },
      "source": [
        "use_cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uah79fPyb1lA"
      },
      "source": [
        "VGG11은 2차원 CONV 8개, Fully Connected 3개로 구성된 11 레이어 CNN 모델  \n",
        "레이어의 채널수\n",
        "- Conv 레이어 3(입력 RGB 3ch)-64-128-256-256-512-512-512-512 Conv\n",
        "- FC 레이어 4096-4096-1000(출력 1000 클래스) FC 레이어\n",
        "\n",
        "\n",
        "- 3,4번 Conv, 5,6번 Conv, 7,8번 Conv 사이에는 MaxPooling을 하지 않아서 feature map 크기가 유지되고 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-okVPgVH40d9"
      },
      "source": [
        "VGG11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQtXz7rP5fVC"
      },
      "source": [
        "마지막 classifier 변수에 두 개의 fully connected layer와 output layer가 있다.  \n",
        "output layer는 classifier[6] 이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTysYUcHdw_r"
      },
      "source": [
        "# 데이터 로더 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-o8pm4Bp0Ht"
      },
      "source": [
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPdU0sMGm5E7"
      },
      "source": [
        "data_dir = '/content/dogImages'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y7l93YJlxXf"
      },
      "source": [
        "## 이번에는 단순히 ToTensor뿐 아니라 이미지에 대해 rotation, resizeCrop, HorizontalFlip, Normalize까지 적용하여 data augmentation 한 후에 학습 진행\n",
        "### 이미지 데이터 augmentation 결과 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbNjmQT_ljcY"
      },
      "source": [
        "data_augmentation_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                                    transforms.RandomResizedCrop(224),\n",
        "                                                    transforms.RandomHorizontalFlip(),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    #transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                    #                     [0.229, 0.224, 0.225])\n",
        "                                                    ])\n",
        "augmented_data = datasets.ImageFolder(train_dir, transform=data_augmentation_transforms)\n",
        "augdata_loader = torch.utils.data.DataLoader(augmented_data, batch_size=20, shuffle=True)\n",
        "\n",
        "# 미니배치 하나에 대해 augmented data 보기\n",
        "for b, l in augdata_loader:\n",
        "    for i in range(len(b)):\n",
        "        print('Image shape:', list(b[i].shape), 'Label:', l[i].numpy(), 'Name:', names[l[i]])\n",
        "        img = b[i].numpy() # tensor를 numpy array로 변환\n",
        "        img = np.transpose(img, (1, 2, 0)) # color 채널 순서 맞춰주기\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNzR7E9sbRB"
      },
      "source": [
        "# 정규화를 적용한 이미지 보기\n",
        "## 정규화는 pretrained model 원본 데이터셋(이미지넷)의 분포에서 계산된 값\n",
        "## torchvision.models 의 모든 모델은 mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] 으로 정규화된 입력을 받도록 학습되어 있음\n",
        "## 참고 링크\n",
        "https://pytorch.org/vision/stable/models.html   \n",
        "https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3fptUFsghv"
      },
      "source": [
        "data_augmentation_transforms_normalized = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                                    transforms.RandomResizedCrop(224),\n",
        "                                                    transforms.RandomHorizontalFlip(),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                         [0.229, 0.224, 0.225])\n",
        "                                                    ])\n",
        "augmented_data_normalized = datasets.ImageFolder(train_dir, transform=data_augmentation_transforms_normalized)\n",
        "augdata_loader_normalized = torch.utils.data.DataLoader(augmented_data_normalized, batch_size=20, shuffle=True)\n",
        "\n",
        "# 정규화된 이미지 보기\n",
        "for b, l in augdata_loader_normalized:\n",
        "    for i in range(5):\n",
        "        print('Image shape:', list(b[i].shape), 'Label:', l[i].numpy(), 'Name:', names[l[i]])\n",
        "        img = b[i].numpy() # tensor를 numpy array로 변환\n",
        "        img = np.transpose(img, (1, 2, 0)) # color 채널 순서 맞춰주기\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u83LolrAniI7"
      },
      "source": [
        "## 전체 데이터로더 구성\n",
        "데이터 augmentation에 데이터 값의 정규화까지 적용.  \n",
        "이미지넷 데이터셋의 정규화 파라미터 적용: [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sD1PJ0TeZo7"
      },
      "source": [
        "data_dir = '/content/dogImages'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                            [0.229, 0.224, 0.225])\n",
        "                                       ])\n",
        "\n",
        "\n",
        "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                               transforms.CenterCrop(224),\n",
        "                               transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "valid_data = datasets.ImageFolder(valid_dir,transform=valid_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=20,shuffle=False)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size=20,shuffle=False)\n",
        "loaders_transfer = {'train':trainloader,\n",
        "                  'valid':validloader,\n",
        "                  'test':testloader}\n",
        "data_transfer = {\n",
        "    'train':trainloader\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH4IPkeD6eXX"
      },
      "source": [
        "# vgg11 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqV0BpKWp55V"
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "model_transfer = models.vgg11(pretrained=True)\n",
        "\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()\n",
        "print(model_transfer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9pjwkioxWg"
      },
      "source": [
        "# pretrained model의 모든 weight를 고정했음 (requires_grad 가 False) \n",
        "# 마지막 출력 레이어인 classifier[6]도 고정된 상태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZE_j3eztpGq"
      },
      "source": [
        "model_transfer.classifier[3].weight.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5TCuR5xq7SJ"
      },
      "source": [
        "model_transfer.classifier[6], model_transfer.classifier[6].weight.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGxe3MLo6ij1"
      },
      "source": [
        "# 출력 레이어가 이미지넷에 맞춰 1000개의 클래스로 되어 있다.\n",
        "# 이 구조를 자신의 문제에 맞춰 바꿔 준다.\n",
        "# dog breed가 133 종류이니 133개의 출력 레이어로 바꾼다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9caNQzuirAFA"
      },
      "source": [
        "model_transfer.classifier[6] = nn.Linear(4096,133,bias=True) # 출력 레이어를 133 출력 노드를 가지는 층으로 변경"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDHR7nYY3b_I"
      },
      "source": [
        "model_transfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9wGv_OqpPcl"
      },
      "source": [
        "# 새로 정의한 레이어는 디폴트로 requires_grad가 True임. 즉 학습할 수 있는 레이어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLlbks_lvkR4"
      },
      "source": [
        "model_transfer.classifier[6], model_transfer.classifier[6].weight.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTTOYZVBpZ_j"
      },
      "source": [
        "# Loss 함수와 Optimizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt2xa_NirXXx"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d60MaliZkVeF"
      },
      "source": [
        "# 학습 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_R4rub_tmND"
      },
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        # 학습 모드로 설정\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']): # 매번 loader에서 하나의 미니 배치를 읽는다\n",
        "            # GPU를 사용하고 있으면 데이터를 cuda 형식으로 변환\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "                model.to('cuda')\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "\n",
        "            # 그래디언트를 0으로 초기화\n",
        "            optimizer.zero_grad()\n",
        "            # 모델의 forward pass를 실행하여 출력을 계산\n",
        "            output = model(data)\n",
        "            # 출력과 target 사이의 loss 계산\n",
        "            loss = criterion(output,target)\n",
        "            # backward pass를 실행하여 그래디언트를 계산\n",
        "            loss.backward()\n",
        "            # weight update\n",
        "            optimizer.step()\n",
        "            # train_loss를 계산\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        # evaluation 모드로 설정 - weight가 update되지 않는다\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            accuracy=0\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            logps = model(data)\n",
        "            loss = criterion(logps, target)\n",
        "            # 학습이 아니므로 backward pass가 없다\n",
        "\n",
        "            # validation loss 계산\n",
        "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uhyc5L4pkvG"
      },
      "source": [
        "## 20 epoch 학습 (or 10 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyQKEru4ukm7"
      },
      "source": [
        "# train the model\n",
        "#model_transfer = train(10, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
        "model_transfer = train(20, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTfZwTo3mNFt"
      },
      "source": [
        "# 모델의 prediction과 target 을 비교하여 accuracy를 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kYAELsKuosB"
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnfUlOljOKuM"
      },
      "source": [
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiy5BSpk6AUu"
      },
      "source": [
        "!ls dogImages/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVByMkIi_nsv"
      },
      "source": [
        "!mkdir my_dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOrF91Du_vP6"
      },
      "source": [
        "!cp dogImages/test/*/*.jpg my_dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk41_0va_1rs"
      },
      "source": [
        "!ls my_dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFT31oCAzqka"
      },
      "source": [
        "dog_files_short = np.array(glob(\"/content/my_dogs/*\"))\n",
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].dataset.classes]\n",
        "\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XGGmawLN5up"
      },
      "source": [
        "# predict function\n",
        "def predict_breed_transfer(img_path, model, classnames):\n",
        "    # load the image and return the predicted breed\n",
        "    \n",
        "    transform = transforms.Compose([transforms.Resize(255),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                         [0.229, 0.224, 0.225])])\n",
        "    img = Image.open(img_path)\n",
        "    img = transform(img)[:3,:,:].unsqueeze(0)\n",
        "    if use_cuda:\n",
        "        img = img.cuda()\n",
        "        model.to('cuda')\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    model.eval()\n",
        "    idx = torch.argmax(model(img))\n",
        "    return class_names[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcQvrtsRAmKn"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txfloLkUAvMI"
      },
      "source": [
        "len(dog_files_short)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMlQiRKjAYpo"
      },
      "source": [
        "all_count = 0\n",
        "correct_count = 0\n",
        "missed_count = 0\n",
        "for fn in dog_files_short[:100]:\n",
        "    img = Image.open(fn)\n",
        "    label = fn.split('/')[-1].split('.')[0][:-6].replace('_', ' ')\n",
        "    print('Ground truth', label)\n",
        "    plt.imshow(np.asarray(img))\n",
        "    plt.show()\n",
        "    #pred = predict_breed_transfer(fn)\n",
        "    pred = predict_breed_transfer(fn, model_transfer, class_names)\n",
        "    print('Prediction', pred)\n",
        "    all_count += 1\n",
        "    if label == pred:\n",
        "        print('CORRECT')\n",
        "        correct_count += 1\n",
        "    else:\n",
        "        print('MISSED')\n",
        "        missed_count += 1\n",
        "    print('------------------------------------------------------------')\n",
        "    #break\n",
        "\n",
        "print(\"Correct results: {:4.2%} ({} out of {})\".format(correct_count/all_count, correct_count, all_count))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLKipSbJXgLn"
      },
      "source": [
        "# 보다 큰 모델로 전이학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU9Gw4hhzyxr"
      },
      "source": [
        "#model_transfer_resnet = models.resnet50(pretrained=True)\n",
        "model_transfer_resnext = models.resnext50_32x4d(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FooIcgkW02ZM"
      },
      "source": [
        "#model_transfer_resnet\n",
        "model_transfer_resnext\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbDV2bv61j-z"
      },
      "source": [
        "#model_transfer_resnet.fc\n",
        "model_transfer_resnext.fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkryx89U09GD"
      },
      "source": [
        "# ResNet50는 출력레이어 이름이 fc이고 2048x1000 구조임 (resnext50도 동일)\n",
        "## 출력레이어를 2048x133으로 바꿔주고 전이학습 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUSN8KotYkYg"
      },
      "source": [
        "# 아래 코드를 그대로 사용하기 위해 이름을 model_transfer_resnet으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8CiXur8YeGo"
      },
      "source": [
        "model_transfer_resnet = model_transfer_resnext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu7X44vi0yhM"
      },
      "source": [
        "for param in model_transfer_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer_resnet = model_transfer_resnet.cuda()\n",
        "\n",
        "# 출력 레이어를 133 출력 노드를 가지는 층으로 변경\n",
        "model_transfer_resnet.fc = nn.Linear(2048, 133, bias=True) \n",
        "\n",
        "# 변경 상태 확인\n",
        "print(model_transfer_resnet)\n",
        "print(model_transfer_resnet.fc.weight.requires_grad)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YQZpYlu_-Fn"
      },
      "source": [
        "# Loss criterion과 optimizer 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rls_2aNL1vGN"
      },
      "source": [
        "criterion_transfer_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_transfer_resnet = optim.SGD(model_transfer_resnet.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ-fDRUd3Fhh"
      },
      "source": [
        "# train 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BDfv5Xj_3iM"
      },
      "source": [
        "# train the model\n",
        "model_transfer_resnet = train(20, loaders_transfer, model_transfer_resnet, optimizer_transfer_resnet, criterion_transfer_resnet, use_cuda, 'model_transfer_resnet.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer_resnet.load_state_dict(torch.load('model_transfer_resnet.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHxExXAk3D6p"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQaaxsjl25Uf"
      },
      "source": [
        "test(loaders_transfer, model_transfer_resnet, criterion_transfer_resnet, use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxVu9pjZ3Hxb"
      },
      "source": [
        "# check prediction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQF4DWx3a1O"
      },
      "source": [
        "# predict function\n",
        "# def predict_breed_transfer(img_path, model, classnames):\n",
        "#     # load the image and return the predicted breed\n",
        "    \n",
        "#     transform = transforms.Compose([transforms.Resize(255),\n",
        "#                                     transforms.CenterCrop(224),\n",
        "#                                     transforms.ToTensor(),\n",
        "#                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
        "#                                                          [0.229, 0.224, 0.225])])\n",
        "#     img = Image.open(img_path)\n",
        "#     img = transform(img)[:3,:,:].unsqueeze(0)\n",
        "#     if use_cuda:\n",
        "#         img = img.cuda()\n",
        "#         model.to('cuda')\n",
        "#     # forward pass: compute predicted outputs by passing inputs to the model\n",
        "#     model.eval()\n",
        "#     idx = torch.argmax(model(img))\n",
        "#     return class_names[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6ZLrSM3CtQ"
      },
      "source": [
        "\n",
        "dog_files_short = np.array(glob(\"/content/my_dogs/*\"))\n",
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].dataset.classes]\n",
        "\n",
        "model_transfer_resnet.load_state_dict(torch.load('model_transfer_resnet.pt'))\n",
        "\n",
        "all_count = 0\n",
        "correct_count = 0\n",
        "missed_count = 0\n",
        "for i, fn in enumerate(dog_files_short[:100]):\n",
        "    img = Image.open(fn)\n",
        "    label = fn.split('/')[-1].split('.')[0][:-6].replace('_', ' ')\n",
        "    print(i)\n",
        "    print('Ground truth', label)\n",
        "    plt.imshow(np.asarray(img))\n",
        "    plt.show()\n",
        "    pred = predict_breed_transfer(fn, model_transfer_resnet, class_names)\n",
        "    print('Prediction', pred)\n",
        "    all_count += 1\n",
        "    if label == pred:\n",
        "        print('CORRECT')\n",
        "        correct_count += 1\n",
        "    else:\n",
        "        print('MISSED')\n",
        "        missed_count += 1\n",
        "    print()\n",
        "    #break\n",
        "\n",
        "print(\"Correct results: {:4.2%} ({} out of {})\".format(correct_count/all_count, correct_count, all_count))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLH3k7kQzRdF"
      },
      "source": [
        "# 끝"
      ]
    }
  ]
}